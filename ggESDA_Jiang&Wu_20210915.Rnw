\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}
\usepackage{float} %for figure [H]
%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}
\newcommand{\imgdir}{../../../paperImage/}
%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
%\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
#options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
#library("MASS")
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Bo-Syue Jiang\\National Taipei University
\And Han-Ming Wu\\National Chengchi University}
\Plainauthor{Bo-Syue Jiang,Han-Ming Wu}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{ggESDA: An \proglang{R} Package for Exploratory Symbolic Data Analysis using \pkg{ggplot2}}
\Plaintitle{A Short Demo Article: Regression Models for Count Data in R}
\Shorttitle{A Short Demo Article in \proglang{R}}

%% - \Abstract{} almost as usual
\Abstract{
  This paper presents the \pkg{ggESDA} package, which we developed for exploratory symbolic data analysis in \proglang{R}. Based on \pkg{ggplot2} \cite{Wickham:2009}, the \pkg{ggESDA} package which is familiar programming structure with its parent provides a wide variety of graphical techniques such as histogram, 3D-scatterplot and radar plot. In addition, a general and  customized transformation function \code{classic2sym()} is implemented for generating a symbolic data table from classical data frame by clustering algorithm, \pkg{RSDA} \cite{Rojas:2015} function and user-defined method. wait for edit......
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{data visualization, symbolic data analysis, exploratory data analysis, \pkg{ggplot2} extensions, interval-valued data, \proglang{R}}
\Plainkeywords{data visualization, symbolic data analysis, exploratory data analysis, ggplot2 extensions, interval-valued data, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).

<<dataPrepare, echo=FALSE, results=hide>>=
library(ggESDA)
library(grid)
library(gridExtra)
set.seed(20211020)
myDiamonds <- diamonds
myDiamonds.i <- classic2sym(myDiamonds)$intervalData
breastData <- data.table::fread("doc/data.csv")
@



\begin{document}
%\SweaveOpts{concordance=TRUE} 
\section{Introduction}
"In Data Science the aim is to extract new knowledge from Standard, Big, and complex data. Often these data are unstructured with variables defined on different kinds of units. They can also be multi-sources (as mixtures of numerical and textual data, with images and networks)." \cite{Diday:2018}. The statement indicates that not only conventional data but the unstructured data, also known as symbolic data, is vital for data science. Rather than the classical data represented by a single value, symbolic data with measurements on $p$ random variables can be $p$-dimensional statistical units such as hypercubes or histograms. The field of symbolic data analysis (SDA) \cite{Billard+Diday:2007} is to broaden the application aspects of statistical methodologies, extend traditional cognition of a form of data unit and build a brand-new analysis system of data science. Recent developments in the field of big data analytics have led to a renewed interest in complex structure data such as symbolic data. As shown in Figure \ref{fig:trend}, the number of researches in SDA represents an increasing trend from 1998 to 2020, which outstands the importance of it during the years.
\begin{figure}[h]	
  		\centering	 			 	 
 	 		\includegraphics[width=1\textwidth]{\imgdir Trend_SDA_1998_to_2020.png} 
  		\caption{The number of "symbolic data analysis" or "interval-valued data" related articles in researches and applications according to PubMed and ScienceDirect online database over time from 1998 to 2020.}   		
  		\label{fig:trend}   			 		 
\end{figure}
Among ScienceDirect, Engineering and Computer Science lead the subject areas obviously, shown in Figure \ref{fig:subjectAreas}.
\begin{figure}[h]	
  		\centering	 			 	 
 	 		\includegraphics[width=1\textwidth]{\imgdir subjectAreas_scienceDirect.png} 
  		\caption{Top 10 researches and applications domains for SDA or interval-valued data (ScienceDirect) from 1998 to 2020} 
  		\label{fig:subjectAreas}   			 		 
\end{figure}


In practice, the symbolic data is often generated by aggregating massive datasets into intervals in order to make the management easy and appropriate. An interval-valued symbolic random variable $X$, taking values in interval, can be denoted such as $X = [a,b] \subset  R^{1}$, where $a \leq b$, and $a, b \in R^{1}$. Let the random variable $X$, for instance, be the weight, then $X = [50,100]$ represents the interval covering the weight of people. With the advent of big data analytic, interval-valued data is becoming more common and accessible than ever. The researches for interval-valued data such as the sign test for COVID-19 data \cite{sherwani:2021}, the prediction via regularized artificial neural network \cite{yang:2019}, a bivariate Bayesian method for regression models \cite{xu:2021}, etc.

Exploratory Data Analysis (EDA) \cite{Tukey:1977} is primarily used to see what data can reveal beyond the formal modeling or hypothesis testing task, provides an overview of raw datasets and obtains a general understanding about the variables and their relationships.


\section{Prominent SDA packages}

\subsection[RSDA]{\pkg{RSDA}}

\subsection[symbolicDA]{\pkg{symbolicDA}}

\subsection[HistDAWass]{\pkg{HistDAWass}}




\section[Basic usage of ggESDA]{Basic usage of \pkg{ggESDA}}

\pkg{ggESDA} is now available from the Github at \url{https://github.com/kiangkiangkiang/ggESDA}. All reference manual documented by exported functions and introduction vignettes can also be download here. In the following section, we are going to illustrate the functionalities and syntaxes about \pkg{ggESDA}.

\subsection[Transformation function]







\subsection{General principles}

\subsection{Multiple plot}

\subsection{Package dependencies}


\section{Application to real datasets}

\subsection{univariate}

\subsection{bivariate}

\subsection{multivariate}


\section{Conclusion}





\section{why SDA plot (weakness of classical plot)}
\subsection{sol overstike}
For the conventional exploratory data analysis, it is always a severe challenge to deal with enormous datasets because conventional displays suffered from overstrikes of data points representing the value (scatterplot type displays) or overstrikes of line segments connecting values of neighboring variables. As a consequence, exploratory symbolic data analysis (SDA) becomes a preliminary yet essential tool for summarizing the main characteristics of a data set before appropriate statistical modeling can be applied. Besides escaping the problem mentioned above, SDA can effectively reduce observations in data, which will make the study focus on what we interesting instead of unnecessary information such as Figure~\ref{fig:compare}.

\begin{figure}[H]
\centering
<<compare, echo=FALSE, fig=TRUE, height=5.2, width=7>>=
myOrder <- c(5, 4, 3, 1, 2)
myCol <- RColorBrewer::brewer.pal(5, "Blues")

a <- ggplot(myDiamonds, aes(x = carat, y = price))+
  geom_point() + theme_bw()
b <- ggInterval_scatter(myDiamonds.i, aes(x = carat, y = price)) + 
  scale_fill_manual(values = myCol[myOrder], 
                    name="Kmeans-Group", 
                    labels = c(1:5)) + theme_bw()

grid.arrange(a, b, ncol=2, widths=c(1.5, 2))
@
\caption{\label{fig:compare} Compare classical data and symbolic data}
\end{figure}

In Figure~\ref{fig:compare}, we can clearly visualize the scatter plot in the right hands, which is represented by symbolic data and aggregated by K-means \cite{Jin:2010}. 


\subsection{full information}

In the past, we would like to use barplot to visualize the frequency of categorical data, but that was merely represented the distribution of full data in that category. It cannot lead researchers to explore more details in what they are interesting such as a particular part of data, so aggregation methods play a vital role to merge the data we interesting.

However, the conventional categorical data after merging will usually be represented by mode, which will be unmeaningful to visualize and cause the loss of information that may become larger when the data or the number of factors in that category is growing on. SDA will build a histogram by calculating each factor of the category of frequency as bins to solve this kind of problem as a result. In that way, a categorical variable will never be shown as a single value at all, instead, a complete information histogram will be substituted.


\section{classical data to symbolic data}

\subsection{datasets}

We will apply the breast mass dataset, which is computed from a digitized image of a fine needle aspirate (FNA), to demonstrate how does a classical dataset transforms into a symbolic dataset. The breast mass dataset describe characteristics of the cell nuclei present in the image. It can be downloaded from the kaggle at \url{https://www.kaggle.com/uciml/breast-cancer-wisconsin-data?select=data.csv}. There are 569 observations and 32 variables in the dataset. We are going to store this dataset in \code{breastData} as data frame type in \proglang{R}, and the variables will be shown as follows:
<<show_breastData_attr>>=
colnames(breastData)
@

Except for the first two variables, they are all composed of mean, standard error, and "worst" in their own field respectively.

\subsection{K-means}

K-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean. In \pkg{ggESDA}, the algorithm will be based on the \pkg{stats} package, and the number of k is a parameter that user can define themself:

<<classic2sym_kmeans>>=
breastData <- dplyr::select(breastData, -id)
breastData.sym <- classic2sym(breastData, groupby = "kmeans", k = 5)
breastData.sym.i <- breastData.sym$intervalData
as.data.frame(head(breastData.sym.i[, 1:4], 5))
@

The \code{id} is unused in this case, so we remove it by \pkg{dplyr}. Then using \code{classic2sym} to aggregate \code{breastData}. It will return several result sets include clustering result and interval-valued data, etc. The interval-valued data can be extracted by \code{$intervalData}, and it will be presented by the package of \pkg{RSDA} type.

The \code{groupby} is a parameter that determine what kind of aggregation methods will be used. Whenever the K-means method is applied, the consequent \code{k} will become meaningful, whereas the other situation is not. It is also a default method when users have no input arguments in \code{groupby}.

\subsection{Hierarchical}

The second well-known clustering algorithm is called Hierarchical clustering \cite{Cecil:1966}, also called hierarchical cluster analysis or HCA. It can be performed with a distance matrix
calculated by raw data and used to present the distance of each cluster. In basic \proglang{R} package, it is also realized by \pkg{stats}, which the \pkg{ggESDA} is based on for implementing HCA:

<<classic2sym_hclust>>=
breastData.sym <- classic2sym(breastData, groupby = "hclust")
breastData.sym.i <- breastData.sym$intervalData
@

Remark that the \code{k} parameter is not meaningful in the case without K-means clustering. In \code{classic2sym}, the keywords of HCA is called \code{hclust}.

\subsection{particular variable}

Using a particular variable to merge different data is a common way for data analysis, too. \pkg{ggESDA} provides such as this concept in \code{classic2sym} to analyze different factors of category variables, and merge the same factor into the symbolic data type:

<<classic2sym_parVar>>=
breastData.sym <- classic2sym(breastData, groupby = "diagnosis")
breastData.sym.i <- breastData.sym$intervalData
head(breastData.sym.i[, 1:4], 5)
@

In \code{breastData}, the only category variable is \code{diagnosis}, which means the diagnosis of breast tissues (M = malignant, B = benign). We put it as an input argument in \code{groupby} for merging different diagnosis results, and the interval-valued data of result sets will display its factor levels in row names.


\subsection{user defined}

In general, users may not always use the aggregation methods we provide, thus, besides generating a particular variable for the group, \pkg{ggESDA} facilitates the process through the min data and max data that user-defined.

For the demonstration, we will build both min data and max data using \code{runif}. Generate a uniform random variable to make sure that all min data are smaller than max data:

<<classic2sym_parVar>>=
minData <- runif(100, -100, -50)
maxData <- runif(100, 50, 100)
demoData <- data.frame(min = minData, max = maxData)
demoData.sym <- classic2sym(demoData, groupby = "customize", 
                            minData = demoData$min,
                            maxData = demoData$max)

demoData.sym.i <- demoData.sym$intervalData
as.data.frame(head(demoData.sym.i, 5))
@

Then choose the \code{customize} argument in \code{groupby}, input which data are \code{minData} or \code{maxData}, and the transformation will be simply completed.

In order to simplify the process and make the preprocessing friendly, we develop this method and let the people who want to analyze symbolic data easier.


\bibliography{refs}

\end{document}
